---
title: "Schooling Methods in Student Test Scores"
author: Denise Chang
thanks: "Code and data are available at: LINK."
date: today
date-format: long
abstract: "An increasing number of schools and universitities have adopted virtual or hybrid teaching methods ever since the COVID-19 pandemic in 2020. Using data from the National Center for Education Statistics and from various district-level assessements, this paper investigates the impact of schooling modes on students' pass rate in state standardized assessments in grades 3-8 during the 2020-2021 school year. The exploration of the data across 11 states suggests that the overall student pass rates declined during the pandemic school year. The pass rates have also seen more drastic changes in schools who had a higher share of virtual and hybrid schooling. The results of this study are significant as they can be used by educational authorities and policymakers to support student learning."
format: pdf
number-sections: true
bibliography: references.bib
---

NOTE TO SELF : I WANT TO CHANGE THE FIRST SENTENCE IN ABSTRACT

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(knitr)
library(here)
library(arrow)
library(gridExtra)
```

# Introduction

In 2020, the World's Health Organization (WHO) declared the coronavirus disease, commonly known as COVID-19, a public health emergency of international concern [@WHO]. As an airborne disease, COVID-19 was highly contagious from person to person, which made virtually all lifestyle activities a health risk during the pandemic. During this time, hosting in-person classroom activities and instructional periods were also considered a health hazard and were strongly discouraged. It attempts to support students and staff despite the uncertainty and unpredictability of the pandemic, school leaders and authorities implemented alternative learning models which offered students the opportunity to continue their studies in a safe way. In the United States, hybrid and virtual schooling modes were commonly adopted in 2020-2021 in response to the pandemic. **ANOTHER TRANSITION SENTENCE?**

In this paper, I am interested in the impact of different schooling methods on US students' pass rates on state standardized exams in the pandemic school year in 2020-2021. Using district-level databases from 11 states and well as data from the Natiocal Center of Educational Statistics (NCES), I explore the changes in students' pass rates in 2020-2021 for more insights on the influence of the district's chosen learning model on the overall learning outcomes I find that, despite having the same curriculum, the decline in student pass rate is notably more obvious for schools who had a higher share in virtual or hybrid schooling modes. More specifically, (pass rates in English + Math) which results in an overall decline of \_\_\_\_% during the pandemic year. Also, I also find that schools with higher shares of Black and Hispanic students saw a greater decline in student pass rates. **MODIFY THIS IF NEEDED AFTER DISCUSSION** I can maybe show some stats here already??

The remainder of this paper is structured as follows. Section 2 discusses the data collection and the studied variables. Section 3 builds a model that suggests a relationship between learning models and student pass rates. Section 4 presents results and findings of the exploration for the dataset with the help of visualized data. Section 5 explores further insights from section 4 and discusses a few weaknesses and limitations of this study. This section also suggests potential next steps following this paper.

# Data

The data was cleaned and processed using the statistical programming language R [@R]. Statistical libraries such as `tidyverse` [@tidyverse], `knitr` [@knitr], `arrow` [@arrow] and `here` [@here] are leveraged in the data processing as well.

```{r}
#| message: false
#| echo: false

# Read in data
all_data <- read_parquet(here::here("outputs/data/analysis_data.parquet"))
```

## Source and Data Collection

The paper and raw data used for replication is obtained from "Pandemic Schooling Modes and Student Test Scores: Evidence from US School Districts" [@OG], published in the American Economic Association's *American Economic Review: Insights* [@AEA]. The downloaded data is built from district-level schooling mode data from the 2020-2021 schooling year and from district-level standardized assessment data from Spring 2019-2019 and 2021. I also downloaded additional district-level demographic data for this investigation. Detailed explanation of each data source and data collection method is given below.

### District-Level Schooling Methods

Data on district-level schooling methods are downloaded from the COVID-19 School Data Hub [@datahub]. This is a public database which aggregates state-sourced data to provide information on schooling modes and learning models by school districts during the 2020-2021 school year. Typically, the state-sourced data are State Education Agencies (SEA).

```{r}
#| message: false
#| echo: false
#| label: tbl-schooling_data
#| tbl-cap: First Six Rows of the Schooling Modes Data by District ID in 2020-2021 School Year

# visualize the first 6 rows of the data
mode_data <-
  all_data |>
  filter(year == 2021) |>
  select(leaid, share_inperson, share_virtual, share_hybrid) |>
  slice(1:6) |>
  mutate(share_inperson = round(share_inperson * 100, 2),
         share_virtual = round(share_virtual * 100, 2), 
         share_hybrid = round(share_hybrid * 100, 2)) |>
  kable(col.names = c("District ID", "In-person Model (%)", "% Virtual Model (%)", "Hybrid Model (%)")
  )

mode_data
```

For each district in the United States, @tbl-schooling_data provides information on the percentage of the academic spent in each of type of schooling methods. To collect this data, the COVID-19 School Data Hub Team submitted data requests to state education agencies. They requested records of learning models used by schools and/or districts in the 2020-2021 academic school year. The renewal frequency of the data depends on on each school and districts where some would send new records weekly, while others would send the records in monthly. States who provided data monthly, bi-weekly or weekly during 2020-2021 year were included in this analysis.

### District-Level Assessment Data

Data on district-level assessment results are collected from the Departments of Educations for the studied states. The respective departments collect data via surveys from constituent schools, school authorities and school boards [@USeducation]. To evaluate changes in students' pass rates in math and ELA, data on test scores between Spring 2016-2019 and 2021 were extracted. @tbl-rates_data is a sample of this data and is organized by year of study between grade 3 and grade 8.

```{r}
#| message: false
#| echo: false
#| label: tbl-rates_data
#| tbl-cap: First Six Rows of the Pass Rates by District ID, Subject and Grade from 2016-2019

# visualize the first 6 rows of the data
rate_data <-
  all_data |>
  select(leaid, subject, year, pass3, pass4, pass5, pass6, pass7, pass8) |>
  slice(1:6) |>
  mutate(pass3 = round(pass3 * 100, 2),
         pass4 = round(pass4 * 100, 2),
         pass5 = round(pass5 * 100, 2),
         pass6 = round(pass6 * 100, 2),
         pass7 = round(pass7 * 100, 2),
         pass8 = round(pass8 * 100, 2),) |>
  arrange(leaid) |>
  kable(col.names = c("District ID", "Subject", "Year", "Grade 3 (%)", "Grade 4 (%)", "Grade 5 (%)", "Grade 6 (%)", "Grade 7 (%)", "Grade 8 (%)")
  )

rate_data
```

The downloaded dataset includes states which had at least two years of pre-pandemic test data available and had no significant changes to the assessment content. Certain states such as Alaska, Nevada and New York were were excluded from the analysis as these states presented low assessment participation rate in 2021. Based on the state selection criteria previously discussed, the final analysis data captures 11 majors states in the United States: Colorado (CO), Connecticut (CT), Massachusetts (MA), Minnesota (MN), Mississippi (MS), Ohio (OH), Rhode Island (RI), Virginia (VA), West Virginia (WV), Wisconsin (WI) and Wyoming (WY).

## Variables of Interest

### Schooling Modes

The possible schooling modes are in-person, virtual and hybrid learning models. In the analysis data, the schooling modes are defined and determined as follows:

-   In-person: All or most students have access to traditional in-person instruction five days a week.

-   Virtual: All or most students receive instruction online five days a week. Online instruction includes synchronous, asynchronous or a combination of synchronous and asynchronous activities.

-   Hybrid: Schooling modes that do not correspond to any of the previous two models. Usually, this is a combination of the previous two.

### Pass rates

Pass rates are calculated by dividing the number of students who passes standardized assessment by the number of students who took the exam in the district. For the purpose of this analysis, the pass rates for math and ELA assessments were considered. To count a pass, the student must score proficient of above on the selected state assessments.

# Model

Through the exploration and the analysis of the data, I discover there is a correlation between learning model shares and students' pass rates on state assessments. To infer the efficiency of each learning models, we construct a Bayesian generalized linear model.

## Model set-up

The model is run in R [@R] using the `rstanarm` package of @rstanarm using the default priors from `rstanarm`. The estimating equating is as follows:

```{=tex}
\begin{align}
Y_{i} &= \beta_0 + \beta_1 \times \mbox{in-person} + \beta_2 \times \mbox{virtual} + \beta_3 \times \mbox{hybrid} + \epsilon\\
\beta_0 &\sim \text{Normal}(0, 2) \\
\beta_1 &\sim \text{Normal}(0, 2) \\
\beta_2 &\sim \text{Normal}(0, 2) \\
\beta_3 &\sim \text{Normal}(0, 2)
\end{align}
```

In this model, we define the variables as follows:

-   $Y_i$ is students' pass rates on the math and ELA state standardized assessments. 

-   $\beta_0$ is the coefficient for intercept.

-   $\beta_1$ is the coefficient of the percentage of time spent in an in-person learning model.

-   $\beta_2$ is the coefficient of the percentage of time spent in a virtual learning model.

-   $\beta_3$ is the coefficient of the percentage of time spent in a hybrid learning model.

-   $\epsilon$ is the fixed effects from districts, years and location. 

## Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...
how to justify a model????
results of model + summary()

# Results
```{r}
#| include: false
#| warning: false
#| message: false

# Construct summarized pass rate data
clean_data <-
  all_data |>
  mutate(pass_rate = (pass3 + pass4 + pass5 +pass6 + pass7 + pass8) / 6) |>
  select(pass_rate, year, subject, share_inperson, share_virtual, share_hybrid) |>
  mutate(pass_rate = pass_rate * 100,
         share_inperson = share_inperson * 100,
         share_virtual = share_virtual * 100,
         share_hybrid = share_hybrid * 100)

# Filter math data
math_data <-
  clean_data |>
  filter(subject == "math")

# Filter ELA data
ela_data <-
  clean_data |>
  filter(subject == "ela")

```


## In-person learning model on pass rates
```{r}
#| label: fig-in-person
#| echo: false
#| message: false
#| fig-cap: "Enrollment-weighted average change in pass rates in Math standardised tests by the percent of in-person learning."

# Prepare data for in-person learning model in MATH
sorted_math_inperson <- 
  math_data |>
  mutate(inperson_group = cut(share_inperson,
                              breaks = c(0, 25, 50, 75, 100),
                              labels = c("0-25%", "25-50%", "50-75%", "75-100%"),
                              include.lowest = TRUE))
average_pass_rates <- 
  sorted_math_inperson |>
  group_by(year, inperson_group) |>
  summarise(average_pass_rate = mean(pass_rate, na.rm = TRUE))

# Shape to wide format
df_wide <- average_pass_rates |> 
  spread(key = year, value = average_pass_rate)

# Calculate the changes for specified year pairs
df_wide <- 
  df_wide |>
  mutate(`change_2016-2017` = `2017` - `2016`,
         `change_2017-2018` = `2018` - `2017`,
         `change_2018-2019` = `2019` - `2018`,
         `change_2019-2021` = `2021` - `2019`)

# Reshape back to long format
long_filtered_test_data <- 
  df_wide |>
  pivot_longer(cols = starts_with("change_"),
               names_to = "year",
               values_to = "change_in_pass_rate")

# Plot the resultant graph
in_person_math <-
  ggplot(long_filtered_test_data, aes(x = change_in_pass_rate, y = inperson_group, color = factor(year))) +
  geom_point(size = 4) + 
  geom_vline(xintercept = 0, color = "darkgrey") +
  labs(x = "Average Change in Pass Rate in Math (%)", y = "Percent In-Person") +
  scale_color_discrete(labels = c("Spring 2017", "Spring 2018", "Spring 2019", "Spring 2021")) +
  labs(color = "Year Category") +
  theme_minimal()

# Prepare data for in-person learning model in ELA
sorted_ela_inperson <- 
  ela_data |>
  mutate(inperson_group = cut(share_inperson,
                              breaks = c(0, 25, 50, 75, 100),
                              labels = c("0-25%", "25-50%", "50-75%", "75-100%"),
                              include.lowest = TRUE))
average_pass_rates <- 
  sorted_ela_inperson |>
  group_by(year, inperson_group) |>
  summarise(average_pass_rate = mean(pass_rate, na.rm = TRUE))

# Shape to wide format
df_wide <- average_pass_rates |> 
  spread(key = year, value = average_pass_rate)

# Calculate the changes for specified year pairs
df_wide <- 
  df_wide |>
  mutate(`change_2016-2017` = `2017` - `2016`,
         `change_2017-2018` = `2018` - `2017`,
         `change_2018-2019` = `2019` - `2018`,
         `change_2019-2021` = `2021` - `2019`)

# Reshape back to long format
long_filtered_test_data <- 
  df_wide |>
  pivot_longer(cols = starts_with("change_"),
               names_to = "year",
               values_to = "change_in_pass_rate")

# Plot the resultant graph
in_person_ela <-
  ggplot(long_filtered_test_data, aes(x = change_in_pass_rate, y = inperson_group, color = factor(year))) +
  geom_point(size = 4) + 
  geom_vline(xintercept = 0, color = "darkgrey") +
  labs(x = "Average Change in Pass Rate in ELA (%)", y = "Percent In-Person") +
  scale_color_discrete(labels = c("Spring 2017", "Spring 2018", "Spring 2019", "Spring 2021")) +
  labs(color = "Year Category") +
  theme_minimal()

# Combine both graphs 
grid.arrange(
  in_person_math, in_person_ela,
  nrow = 1, 
  heights = c(1, 1)
)
```


## Virtual learning model on pass rates

## Hybrid learning model on pass rates
Percent in-person (math/english)
Percent virtual (math/english)
Percent hybrid (math/english)

do the graphs with the dots (see what other people did)

# Discussion
mental health component of virtual learning (social kakashi, health kakashi)

transition to virtual => learning to adapt a lot of trial and error

difference between grades? =>younger had less difference since their curriculum is easier to understand?

difference between demographic => maybe there was something to discuss about resources

## First discussion point

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this.

## Second discussion point

## Third discussion point

## Weaknesses and next steps
### Weaknesses
A weakness in using data from the 

weakness 1 : missing data => data failed test
weakness 2 : definiton of in-person instruction. Access to in-perosn does not mean everyone actually did it online. Some may have opted to do it online for health reasons. 

### Next steps
testing are only one way to evaluate student learning such as peer assessment + self-assessments

 \newpage 

# References
